{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\langchain\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model = 'gemini-1.0-pro',convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\langchain\\myenv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:310: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hi\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\":\"Hi\"},\n",
    "                     {\"output\":\"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get ouput of load memory variables in list form\n",
    "memory2 = ConversationBufferMemory(return_messages=True)\n",
    "memory2.save_context({\"input\":\"Hi\"},{\"output\":\"What's up\"})\n",
    "memory2.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm = model,verbose =True, memory = ConversationBufferMemory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I help you today?\n",
      "Human: Nothing much just tell me how do conversation with AI\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"* **Be clear and concise.** When you're talking to an AI, it's important to be clear and concise in your language. This will help the AI to understand what you're asking and to respond appropriately.\\n* **Be patient.** AI is still under development, and it may not always be able to understand you perfectly. Be patient and try to rephrase your question if the AI doesn't understand.\\n* **Be open-minded.** AI is constantly learning and evolving. Be open-minded to new ways of thinking and interacting with AI.\\n* **Have fun!** Talking to AI can be a fun and rewarding experience. Don't be afraid to ask questions and explore different ways of interacting with AI.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Nothing much just tell me how do conversation with AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I help you today?\n",
      "Human: Nothing much just tell me how do conversation with AI\n",
      "AI: * **Be clear and concise.** When you're talking to an AI, it's important to be clear and concise in your language. This will help the AI to understand what you're asking and to respond appropriately.\n",
      "* **Be patient.** AI is still under development, and it may not always be able to understand you perfectly. Be patient and try to rephrase your question if the AI doesn't understand.\n",
      "* **Be open-minded.** AI is constantly learning and evolving. Be open-minded to new ways of thinking and interacting with AI.\n",
      "* **Have fun!** Talking to AI can be a fun and rewarding experience. Don't be afraid to ask questions and explore different ways of interacting with AI.\n",
      "Human: How many tips are there can you mention it in numbers?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"How many tips are there can you mention it in numbers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Nothing much just tell me how do conversation with AI', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"* **Be clear and concise.** When you're talking to an AI, it's important to be clear and concise in your language. This will help the AI to understand what you're asking and to respond appropriately.\\n* **Be patient.** AI is still under development, and it may not always be able to understand you perfectly. Be patient and try to rephrase your question if the AI doesn't understand.\\n* **Be open-minded.** AI is constantly learning and evolving. Be open-minded to new ways of thinking and interacting with AI.\\n* **Have fun!** Talking to AI can be a fun and rewarding experience. Don't be afraid to ask questions and explore different ways of interacting with AI.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How many tips are there can you mention it in numbers?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How can I help you today?\n",
      "Human: Nothing much just tell me how do conversation with AI\n",
      "AI: * **Be clear and concise.** When you're talking to an AI, it's important to be clear and concise in your language. This will help the AI to understand what you're asking and to respond appropriately.\n",
      "* **Be patient.** AI is still under development, and it may not always be able to understand you perfectly. Be patient and try to rephrase your question if the AI doesn't understand.\n",
      "* **Be open-minded.** AI is constantly learning and evolving. Be open-minded to new ways of thinking and interacting with AI.\n",
      "* **Have fun!** Talking to AI can be a fun and rewarding experience. Don't be afraid to ask questions and explore different ways of interacting with AI.\n",
      "Human: How many tips are there can you mention it in numbers?\n",
      "AI: 4\n",
      "Human: Can you give me the 3rd tip\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'**Be open-minded.** AI is constantly learning and evolving. Be open-minded to new ways of thinking and interacting with AI.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = \"Can you give me the 3rd tip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory\n",
    "The number of tokens being used for this conversation is greater than when using the ConversationBufferMemory,so is there any advantage to using ConversationSummaryMemory over the buffer memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.save_context({\"input\":\"Hi\"}\n",
    "                           ,{\"output\":\"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.save_context({\"input\":\"Not much,just hanging\"},\n",
    "                           {\"output\":\"cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much,just hanging\\nAI: cool'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k=2,return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.save_context({\"input\":\"hi\"},\n",
    "                           {\"output\":\"What's up\"})\n",
    "window_memory.save_context({\"input\":\"Not much,just hanging\"},\n",
    "                           {\"output\":\"cool\"})\n",
    "window_memory.save_context({\"input\":\"ok thanks\"},\n",
    "                           {\"output\":\"great thank you\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Not much,just hanging', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='cool', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='ok thanks', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='great thank you', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_window = ConversationChain(llm = model,verbose = True,memory = window_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='ok thanks', additional_kwargs={}, response_metadata={}), AIMessage(content='great thank you', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hi,What's up\", additional_kwargs={}, response_metadata={}), AIMessage(content='Not much,just hanging', additional_kwargs={}, response_metadata={})]\n",
      "Human: Hi,What's up\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Not much,just hanging'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.predict(input = \"Hi,What's up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content=\"Hi,What's up\", additional_kwargs={}, response_metadata={}), AIMessage(content='Not much,just hanging', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hi,What's up\", additional_kwargs={}, response_metadata={}), AIMessage(content='Not much,just hanging', additional_kwargs={}, response_metadata={})]\n",
      "Human: How to talk with AI give me five points\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"1. **Be clear and concise.** AI is not as good as humans at understanding natural language, so it's important to be as clear and concise as possible when communicating with it.\\n2. **Use specific examples.** When asking a question or giving a command, try to provide specific examples to help the AI understand what you're looking for.\\n3. **Be patient.** AI is still under development, so it may not always be able to understand you perfectly. Be patient and try to rephrase your question or command if the AI doesn't understand the first time.\\n4. **Don't be afraid to ask for help.** If you're having trouble communicating with the AI, don't be afraid to ask for help from a human.\\n5. **Have fun!** Communicating with AI can be a lot of fun. Experiment with different ways of talking to the AI and see what it can do.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.predict(input = \"How to talk with AI give me five points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content=\"Hi,What's up\", additional_kwargs={}, response_metadata={}), AIMessage(content='Not much,just hanging', additional_kwargs={}, response_metadata={}), HumanMessage(content='How to talk with AI give me five points', additional_kwargs={}, response_metadata={}), AIMessage(content=\"1. **Be clear and concise.** AI is not as good as humans at understanding natural language, so it's important to be as clear and concise as possible when communicating with it.\\n2. **Use specific examples.** When asking a question or giving a command, try to provide specific examples to help the AI understand what you're looking for.\\n3. **Be patient.** AI is still under development, so it may not always be able to understand you perfectly. Be patient and try to rephrase your question or command if the AI doesn't understand the first time.\\n4. **Don't be afraid to ask for help.** If you're having trouble communicating with the AI, don't be afraid to ask for help from a human.\\n5. **Have fun!** Communicating with AI can be a lot of fun. Experiment with different ways of talking to the AI and see what it can do.\", additional_kwargs={}, response_metadata={})]\n",
      "Human: can you tell me how many tips you have generated\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I have generated 5 tips on how to talk with AI.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.predict(input = \"can you tell me how many tips you have generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Not much,just hanging', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='cool', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ok thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='great thank you', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Hi,What's up\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Not much,just hanging', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"Hi,What's up\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Not much,just hanging', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How to talk with AI give me five points', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"1. **Be clear and concise.** AI is not as good as humans at understanding natural language, so it's important to be as clear and concise as possible when communicating with it.\\n2. **Use specific examples.** When asking a question or giving a command, try to provide specific examples to help the AI understand what you're looking for.\\n3. **Be patient.** AI is still under development, so it may not always be able to understand you perfectly. Be patient and try to rephrase your question or command if the AI doesn't understand the first time.\\n4. **Don't be afraid to ask for help.** If you're having trouble communicating with the AI, don't be afraid to ask for help from a human.\\n5. **Have fun!** Communicating with AI can be a lot of fun. Experiment with different ways of talking to the AI and see what it can do.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='can you tell me how many tips you have generated', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I have generated 5 tips on how to talk with AI.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_window.memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='How to talk with AI give me five points', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"1. **Be clear and concise.** AI is not as good as humans at understanding natural language, so it's important to be as clear and concise as possible when communicating with it.\\n2. **Use specific examples.** When asking a question or giving a command, try to provide specific examples to help the AI understand what you're looking for.\\n3. **Be patient.** AI is still under development, so it may not always be able to understand you perfectly. Be patient and try to rephrase your question or command if the AI doesn't understand the first time.\\n4. **Don't be afraid to ask for help.** If you're having trouble communicating with the AI, don't be afraid to ask for help from a human.\\n5. **Have fun!** Communicating with AI can be a lot of fun. Experiment with different ways of talking to the AI and see what it can do.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='can you tell me how many tips you have generated', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='I have generated 5 tips on how to talk with AI.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationEntityMemory\n",
    "\n",
    "Entiy:\n",
    "1) Person -> Shoaib, Mukul\n",
    "2) Location -> Lucknow, Kanpur Delhi\n",
    "3) Organisation -> Google, Nagarro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationEntityMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationEntityMemory(llm = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = {\"input\":\"I am very hungry\"}\n",
    "memory.load_memory_variables(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {'Shoaib': '', 'Mukul': ''}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = {\"input\":\"Shoaib & Mukul are working on a hackathon project\"}\n",
    "memory.load_memory_variables(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {'John': '', 'Kashmir': ''}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = {\"input\":\"My name is John and i am planning trip to kashmir\"}\n",
    "memory.load_memory_variables(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '', 'entities': {'Shoaib': ''}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_input = {\"input\":\"Shoaib is great person who values gratitud.\"}\n",
    "memory.load_memory_variables(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"Human\":\"Shoaib and Mukul are working on a hackathon project\"},\n",
    "    {\"AI\":\"That's awesome! What's the hackathon project about?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Shoaib and Mukul are working on a hackathon project\\nAI: That's awesome! What's the hackathon project about?\",\n",
       " 'entities': {'Shoaib': 'Shoaib is working on a hackathon project with Mukul.'}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\":\"who is Shoaib?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"Human\":\"It's machine learning project focused on healthcare\"},\n",
    "    {\"AI\":\"Sounds Exciting! Are they building a prediction model or something else\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {\"Human\":\"Yes,they are building prediction model\"},\n",
    "    {\"AI\":\"Wishing Shoaib and mukul all the best for their project\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Shoaib and Mukul are working on a hackathon project\\nAI: That's awesome! What's the hackathon project about?\\nHuman: It's machine learning project focused on healthcare\\nAI: Sounds Exciting! Are they building a prediction model or something else\\nHuman: Yes,they are building prediction model\\nAI: Wishing Shoaib and mukul all the best for their project\",\n",
       " 'entities': {'Shoaib': 'Shoaib is working on a machine learning hackathon project focused on healthcare with Mukul, and they are building a prediction model.'}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\":\"who is Shoaib?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Shoaib and Mukul are working on a hackathon project\\nAI: That's awesome! What's the hackathon project about?\\nHuman: It's machine learning project focused on healthcare\\nAI: Sounds Exciting! Are they building a prediction model or something else\\nHuman: Yes,they are building prediction model\\nAI: Wishing Shoaib and mukul all the best for their project\",\n",
       " 'entities': {'Mukul': ''}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\":\"Which project Mukul is working on?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
